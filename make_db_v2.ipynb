{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"p9UkIeKqYP6V"},"outputs":[],"source":["from datetime import timedelta\n","from PIL import Image\n","import cv2\n","import numpy as np\n","import os\n","import shutil"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27302,"status":"ok","timestamp":1667558040665,"user":{"displayName":"Guilherme Rodrigues Monteiro","userId":"07250483182311097967"},"user_tz":180},"id":"1fli_EvKQSXD","outputId":"b05e35e6-ef8c-43ab-d696-df32ef11ab32"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8583,"status":"ok","timestamp":1667558049238,"user":{"displayName":"Guilherme Rodrigues Monteiro","userId":"07250483182311097967"},"user_tz":180},"id":"x3aS-iyZgrfi","outputId":"cc28278e-a2b8-4514-ed99-573976fbe112"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mediapipe\n","  Downloading mediapipe-0.8.11-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.5 MB)\n","\u001b[K     |████████████████████████████████| 31.5 MB 1.4 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.3.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (22.1.0)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.6.0.66)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.21.6)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<4,>=3.11->mediapipe) (1.15.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.4.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.1.1)\n","Installing collected packages: mediapipe\n","Successfully installed mediapipe-0.8.11\n"]}],"source":["!pip install mediapipe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8BvwJ2wKYkia"},"outputs":[],"source":["import mediapipe as mp\n","from mediapipe.python.solutions.drawing_utils import _normalized_to_pixel_coordinates\n","mp_face_detection = mp.solutions.face_detection\n","mp_drawing = mp.solutions.drawing_utils"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1667558049239,"user":{"displayName":"Guilherme Rodrigues Monteiro","userId":"07250483182311097967"},"user_tz":180},"id":"eCcCqizI_ggX","outputId":"b23b554a-c467-4379-87d5-0dcd2d41092c"},"outputs":[{"name":"stdout","output_type":"stream","text":["fusermount: failed to unmount /content/drive: No such file or directory\n","/bin/bash: google-drive-ocamlfuse: command not found\n"]}],"source":["!fusermount -u drive\n","!google-drive-ocamlfuse drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":975,"status":"ok","timestamp":1667558050208,"user":{"displayName":"Guilherme Rodrigues Monteiro","userId":"07250483182311097967"},"user_tz":180},"id":"TZ6UoKLWUqN4","outputId":"c9734113-3767-4501-e46d-2d29b7af9b16"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/Shareddrives/TCC_MLR-Guilherme_Vinicius/Notebooks/Files\n"]}],"source":["%cd /content/gdrive/Shareddrives/TCC_MLR-Guilherme_Vinicius/Notebooks/Files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1YBF7OrGY8Ar"},"outputs":[],"source":["def crop_rate(img, x,y,largura,altura, largura_lfw = 64, altura_lfw = 64, interpolation=cv2.INTER_CUBIC): #cv2.INTER_AREA\n","      razao_aspecto = altura_lfw/largura_lfw\n","      centro_x = x + largura/2\n","      centro_y = y + altura/2\n","      area = largura*altura\n","      largura_adj = np.sqrt(area/razao_aspecto)\n","      altura_adj = razao_aspecto*largura_adj\n","      x_min = int(np.floor(centro_x-largura_adj/2))\n","      x_max = int(np.ceil(centro_x+largura_adj/2))\n","      y_min = int(np.floor(centro_y-altura_adj/2 + 0.5))\n","      y_max = int(np.ceil(centro_y+altura_adj/2 + 0.5)) \n","      if y_min <0:\n","         y_max -= y_min\n","         y_min = 0\n","      if x_min <0:\n","         x_max -= x_min\n","         x_min = 0  \n","      # Centralize and crop\n","      crop_img = img[y_min:y_max, x_min:x_max]\n","      img_lfw = cv2.resize(crop_img, (largura_lfw, altura_lfw), interpolation=interpolation)\n","      #print(img_lfw.shape)\n","      return img_lfw\n","\n","def find_face(image):\n","  with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detection:\n","    # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n","    results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","\n","    if not results.detections:\n","      return False\n","    image_rows, image_cols, _ = image.shape\n","    max_height = 0\n","    for detection in results.detections:\n","      try:\n","        location_data = detection.location_data\n","        relative_bounding_box = location_data.relative_bounding_box\n","        rect_start_point = _normalized_to_pixel_coordinates(relative_bounding_box.xmin, relative_bounding_box.ymin, image_cols,image_rows)\n","        rect_end_point = _normalized_to_pixel_coordinates(relative_bounding_box.xmin+relative_bounding_box.width, relative_bounding_box.ymin+relative_bounding_box.height, image_cols, image_rows)\n","        xleft,ytop = rect_start_point\n","        xright,ybot = rect_end_point\n","        width = xright-xleft\n","        height = ybot-ytop\n","        if height > max_height:\n","          max_height = height\n","          bounding_box = [\n","              xleft, ytop,\n","              width, height,\n","          ]\n","\n","        return bounding_box\n","      except:\n","        return False"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":281,"status":"ok","timestamp":1667566369175,"user":{"displayName":"Guilherme Rodrigues Monteiro","userId":"07250483182311097967"},"user_tz":180},"id":"2VTtv5kVT5fi"},"outputs":[],"source":["SAVING_FRAMES_PER_SECOND = 2 # numero de frames a serem salvos por segundo\n","\n","def format_timedelta(td):\n","    \"\"\"Utility function to format timedelta objects in a cool way (e.g 00:00:20.05) \n","    omitting microseconds and retaining milliseconds\"\"\"\n","    result = str(td)\n","    try:\n","        result, ms = result.split(\".\")\n","    except ValueError:\n","        return result + \".00\".replace(\":\", \"-\")\n","    ms = int(ms)\n","    ms = round(ms / 1e4)\n","    return f\"{result}.{ms:02}\".replace(\":\", \"-\")\n","\n","def get_saving_frames_durations(cap, saving_fps):\n","    \"\"\"A function that returns the list of durations where to save the frames\"\"\"\n","    s = []\n","    # get the clip duration by dividing number of frames by the number of frames per second\n","    clip_duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)\n","    # use np.arange() to make floating-point steps\n","    for i in np.arange(0, clip_duration, 1 / saving_fps):\n","        s.append(i)\n","    return s\n","\n","def make_frames(video_file,fname):\n","    current_filename, _ = os.path.splitext(video_file)\n","\n","    # read the video file    \n","    cap = cv2.VideoCapture(video_file)\n","    # get the FPS of the video\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    # if the SAVING_FRAMES_PER_SECOND is above video FPS, then set it to FPS (as maximum)\n","    saving_frames_per_second = min(fps, SAVING_FRAMES_PER_SECOND)\n","    # get the list of duration spots to save\n","    saving_frames_durations = get_saving_frames_durations(cap, saving_frames_per_second)\n","    # start the loop\n","    count = 0\n","    while True:\n","        is_read, frame = cap.read()\n","        if not is_read:\n","            # break out of the loop if there are no frames to read\n","            break\n","        # get the duration by dividing the frame count by the FPS\n","        frame_duration = count / fps\n","        try:\n","            # get the earliest duration to save\n","            closest_duration = saving_frames_durations[0]\n","        except IndexError:\n","            # the list is empty, all duration frames were saved\n","            break\n","        if frame_duration >= closest_duration:\n","            # if closest duration is less than or equals the frame duration, \n","            # then save the frame\n","            frame_duration_formatted = format_timedelta(timedelta(seconds=frame_duration))\n","            pathname = os.path.join(f\"{fname}frame{frame_duration_formatted}.jpg\")\n","            cv2.imwrite(pathname, frame)\n","            img = cv2.imread(pathname)\n","            face = find_face(img)\n","            if face:\n","              [x, y,largura,altura] = face\n","              gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n","              #print(img.size)\n","              person = crop_rate(gray,x=x,y=y-80,largura=largura,altura=altura+120)\n","              #print(img2.size)\n","              #break\n","              #person = cv2.rotate(person,cv2.ROTATE_180)\n","              cv2.imwrite(pathname, person)\n","              # drop the duration spot from the list, since this duration spot is already saved\n","              try:\n","                  saving_frames_durations.pop(0)\n","              except IndexError:\n","                  pass\n","            else:\n","              os.remove(pathname)\n","        # increment the frame count\n","        count += 1"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":233,"status":"ok","timestamp":1667572640177,"user":{"displayName":"Guilherme Rodrigues Monteiro","userId":"07250483182311097967"},"user_tz":180},"id":"H6hZbwCCnEiU","outputId":"44466e80-2a4f-4b97-a2f9-c5cdea75616c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Cópia de 060822-JoaoPedro-Alto.MPG']"]},"metadata":{},"execution_count":57}],"source":["os.listdir('./Video')"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"CMkMED2MZSlN","executionInfo":{"status":"ok","timestamp":1667572650069,"user_tz":180,"elapsed":7445,"user":{"displayName":"Guilherme Rodrigues Monteiro","userId":"07250483182311097967"}}},"outputs":[],"source":["for video in os.listdir('./Video'):\n","  path = os.path.join(\"./Video\",video)\n","  make_frames(path,'P3')"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[{"file_id":"172H6CjuCMTToqbEuwdarSAE4xfBnams-","timestamp":1663801653606},{"file_id":"1qr5eMdjlUBfb51bJu8DeeQVC2HEuAzRm","timestamp":1658151595445}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}